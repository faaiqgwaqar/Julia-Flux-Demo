{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Flux Breakdown\n",
    "\n",
    "In this demonstration, we take the most basic, but important, building block of deep learning - the perceptron, and build it up to contextualize images. Most of these blocks have brief explainations as to their intention, but if something is confusing, feel free to let me know!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One: A Single Perceptron:\n",
    "Here we will build a single node, and demonstrate the properties of said node. Start with an x and y that we will use as the inputs and expected outputs of our system. Notice the dimentionality of y doesnt correlate with the output of a single perceptron, we will make use of this one later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1]\n",
    "y = [0.6, 0.4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the dense layer constructor, we will create and instance of a single perceptron with one input and one output. This will also be intialized with a sigmoid nonlinearity function (σ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other cool Activations in Flux!\n",
    "# Sigmoid\n",
    "# Tanh\n",
    "# Relu\n",
    "# Elu\n",
    "# Swish\n",
    "\n",
    "single_perceptron_model = Dense(1,1,σ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look through the properties of this model, like its weight and bias terms. This is shown below, we can print out the arrays holding these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_perceptron_model.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_perceptron_model.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we want to see how the model predicts a value on the basis of our input. By using it as a function with the parameter x, we can see how it predicts this value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_perceptron_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this is no different that making use of the weight and the bias terms in the form of a linear equation alongside the sigmoid function. This is shown by calculating this directly below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "σ.(single_perceptron_model.W*[1] + single_perceptron_model.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two: Multi-Dimentionality:\n",
    "Here we will build a chain of outputs to the perceptron, and observe the changes in the weights and bias terms that allow us to visualize this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other cool layers in Flux!\n",
    "# Chain\n",
    "# Conv, DepthwiseConv, ConvTranspose\n",
    "# AdaptiveMaxPool, MaxPool, GlobalMaxPool, GlobalMeanPool\n",
    "# CrossCor, SamePad\n",
    "# ConvFilter, DepthWiseFilter\n",
    "# RNN\n",
    "# LSTM, GRU, Recur\n",
    "# Recur\n",
    "# Maxout, SkipConnection\n",
    "\n",
    "single_dense_model = Dense(1,2,σ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weight and bias arrays are no longer single dimentional. Finally, we can see that perceptrons are built on vector multiplication, and operations like these are optimized when we enter hardware accelerators, GPUs and TPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_dense_model.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_dense_model.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like before, we can test the input to the model, this should be the same as taking the multiplications of these vectors, which each element operating on the inner product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_dense_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "σ.(single_dense_model.W*x + single_dense_model.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Three: Chaining Operations Together:\n",
    "What happpens when we want to add continuous layers together to produce a model. We quickly observe the use of the Chain function, which is the basis of creating larger systems in flux. We know one option to chaining the output to first perceptron to the second, is by placing the call to run the model inside the other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_dense_model(single_perceptron_model([1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But doing so is pretty inefficient, we can get the same result, while saving lines and saving the new model using Chain. Chain will also be helpful as we begin to introduce new deep learning elements to the party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_mlp = Chain(single_perceptron_model,single_dense_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_mlp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Four: Getting The Right Results:\n",
    "Our outputs aren't quite what we wanted. How do we quantify this, and how can we adjust the perceptrons we have to get closer to our desired output. To do this, we need to be able to quantify how far we are, and which way to move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux: mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start by defining loss using a mean squared error operation, which will aggregate the squared error among all of the expected and actual values. Using this, we can find the right direction to move in during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(x,y) = mse(small_mlp(x),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_loss = loss(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets define an optimization algorithm we would like to use. We will make use of the gradient decent with a learning rate of 0.01. Of course, we can use other optimizers, mentioned in comments, with more details in the docs found here:\n",
    "\n",
    "https://fluxml.ai/Flux.jl/v0.8/training/optimisers/#Optimiser-Reference-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other Cool Optimizers in Flux\n",
    "# Update!\n",
    "# Momentup\n",
    "# Neteroc\n",
    "# RADAM\n",
    "# AdaMax\n",
    "# AdaGrad\n",
    "# Adadelta\n",
    "# AmsGrad\n",
    "# NADAM\n",
    "# ADAMw\n",
    "\n",
    "opt = Descent(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the train! function to shift our perceptron parameters in the right direction. Notice that after using the training, we are a little closer to the goal, but we aren't quite there, maybe if we do this enough times we can get it, but how will we do that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flux.train!(loss, params(small_mlp), [(x, y)], opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_loss = loss(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Δ = original_loss - new_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets introduce epochs. Epochs indicate the repetition in training that we would like to observe. As an example, if I want to train ten times, then I would train for ten epochs. We test this macro below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux: @epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@epochs epochs Flux.train!(loss, params(small_mlp), [(x, y)], opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_loss = loss(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Δ = new_loss - epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Five: Go Big Mode\n",
    "We have the building blocks, and understanding of the Flux perceptron, and the knowledge to chain together some layers, but using a dataset of 1, and optimizing only for that isn't something you would ever use a NN model for. We explore the dataloader, and training a model to spec in this next section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will begin to develop our own large dataset, to show how we can use data that hasn't been processed or prepped beforehand. You might notice the transpose - it seems from my own research that Flux doesnt like column vectors, and rather, works appropriately only if you use rows. Weird considering Julia, like Matlab, is column default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = shuffle!(collect(1:1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [i+rand(1:100) for i in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate a quick plot to show our distribution. You might notice the linearity in the curvature, if we could predict a weight to use, we coupld probably predict this line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x,y,seriestype = :scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = transpose(x[1:800])\n",
    "y_train = transpose(y[1:800])\n",
    "x_test = transpose(x[801:1000])\n",
    "y_test = transpose(y[801:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets introduce the dataloader. It will allow us to take these large gatherings of out data, and use the model to train and test it without manually segmenting through batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux.Data: DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataLoader(x_train, y_train, batchsize=50, shuffle=true)\n",
    "test_data = DataLoader(x_test, y_test, batchsize=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we collect multiple different layers to make our multi layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_mlp = Chain(Dense(1,15),Dense(15,20),Dense(20,1,relu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_mlp([x_test[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(x,y) = mse(large_mlp(x),y)\n",
    "loss([x_test[1]],[y_test[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would also like to find a way to define loss across the entire system. We aggregate/avg the loss across all the points to get an all encompasing loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function loss_all(dataloader, model)\n",
    "    l = 0\n",
    "    for (x,y) in dataloader\n",
    "        l += mse(model(x),y)\n",
    "    end\n",
    "    l/length(dataloader)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Descent(1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice we add an additional variable, cb, which reffers to a call back. One use of this, as seen here, is calling back to a visual function that can show us our progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@epochs epochs Flux.train!(loss, params(large_mlp), train_data, opt, cb = () -> @show(loss_all(train_data, large_mlp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Six: Putting it All Together - Working with Images\n",
    "In this final perceptron section, we take an MNIST dataset of image classification for handwrting, and use the building blocks of multilayer perceptrons to contruct identfication of the 9 digits that may exist in each image. Credit to the Flux Model Zoo Github for the original demonstration.\n",
    "\n",
    "https://github.com/FluxML/model-zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot\n",
    "using CUDA\n",
    "using MLDatasets\n",
    "using Flux: onehotbatch, onecold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start by downloading the dataset and visualizing one example, lets observe how this prediction changes with time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, ytrain = MLDatasets.MNIST.traindata(Float32)\n",
    "xtest, ytest = MLDatasets.MNIST.testdata(Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matshow(transpose(xtrain[:,:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As great as simply predicting the exact number is, we will need one hot encoding of the result to dedicate as the result of our system. Using onehotbatch from flux, we can quickly one hot encode the output for our perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain, ytest = onehotbatch(ytrain, 0:9), onehotbatch(ytest, 0:9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want our input to be flattened from the matrix form, to quickly do this we make use of the flatten command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = Flux.flatten(xtrain)\n",
    "xtest = Flux.flatten(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataLoader(xtrain, ytrain, batchsize=1024, shuffle=true)\n",
    "test_data = DataLoader(xtest, ytest, batchsize=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_model = Chain(Dense(28*28, 32, relu), Dense(32, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_model(xtrain[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can work out what our expectations for the prediction would be here, using the max value from the one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findmax(img_model(xtrain[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(x,y) = mse(img_model(x),y)\n",
    "loss(xtrain[:,1],ytrain[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = ADAM(3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@epochs epochs Flux.train!(loss, params(img_model), train_data, opt,cb = () -> @show(loss_all(train_data, img_model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part Seven: An Example of a Truely put together Model\n",
    "In this final section, we briefly explore the conv model for the MNIST data shown above to show how we can construct an even larger, well formated model, but also as an exploration of using GPUs to speed up the computation. Model Zoo used for the demo, link below, thanks!\n",
    "\n",
    "https://github.com/FluxML/model-zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux.Data: DataLoader\n",
    "using Flux.Optimise: Optimiser, WeightDecay\n",
    "using Flux: onehotbatch, onecold\n",
    "using Flux.Losses: logitcrossentropy\n",
    "using Statistics, Random\n",
    "using Logging: with_logger\n",
    "using TensorBoardLogger: TBLogger, tb_overwrite, set_step!, set_step_increment!\n",
    "using ProgressMeter: @showprogress\n",
    "import MLDatasets\n",
    "using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet5 \"constructor\". \n",
    "# The model can be adapted to any image size\n",
    "# and any number of output classes.\n",
    "function LeNet5(; imgsize=(28,28,1), nclasses=10) \n",
    "    out_conv_size = (imgsize[1]÷4 - 3, imgsize[2]÷4 - 3, 16)\n",
    "    \n",
    "    return Chain(\n",
    "            Conv((5, 5), imgsize[end]=>6, relu),\n",
    "            MaxPool((2, 2)),\n",
    "            Conv((5, 5), 6=>16, relu),\n",
    "            MaxPool((2, 2)),\n",
    "            flatten,\n",
    "            Dense(prod(out_conv_size), 120, relu), \n",
    "            Dense(120, 84, relu), \n",
    "            Dense(84, nclasses)\n",
    "          )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_data(args)\n",
    "    xtrain, ytrain = MLDatasets.MNIST.traindata(Float32)\n",
    "    xtest, ytest = MLDatasets.MNIST.testdata(Float32)\n",
    "\n",
    "    xtrain = reshape(xtrain, 28, 28, 1, :)\n",
    "    xtest = reshape(xtest, 28, 28, 1, :)\n",
    "\n",
    "    ytrain, ytest = onehotbatch(ytrain, 0:9), onehotbatch(ytest, 0:9)\n",
    "\n",
    "    train_loader = DataLoader((xtrain, ytrain), batchsize=args.batchsize, shuffle=true)\n",
    "    test_loader = DataLoader((xtest, ytest),  batchsize=args.batchsize)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(ŷ, y) = logitcrossentropy(ŷ, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base.@kwdef mutable struct Args\n",
    "    η = 3e-4             # learning rate\n",
    "    λ = 0                # L2 regularizer param, implemented as weight decay\n",
    "    batchsize = 128      # batch size\n",
    "    epochs = 10          # number of epochs\n",
    "    seed = 0             # set seed > 0 for reproducibility\n",
    "    use_cuda = true      # if true use cuda (if available)\n",
    "    infotime = 1      # report every `infotime` epochs\n",
    "    checktime = 5        # Save the model every `checktime` epochs. Set to 0 for no checkpoints.\n",
    "    tblogger = true      # log training with tensorboard\n",
    "    savepath = \"runs/\"    # results path\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function train(; kws...)\n",
    "    args = Args(; kws...)\n",
    "    args.seed > 0 && Random.seed!(args.seed)\n",
    "    use_cuda = args.use_cuda && CUDA.functional()\n",
    "    \n",
    "    if use_cuda\n",
    "        device = gpu\n",
    "        @info \"Training on GPU\"\n",
    "    else\n",
    "        device = cpu\n",
    "        @info \"Training on CPU\"\n",
    "    end\n",
    "\n",
    "    ## DATA\n",
    "    train_loader, test_loader = get_data(args)\n",
    "    @info \"Dataset MNIST: $(train_loader.nobs) train and $(test_loader.nobs) test examples\"\n",
    "\n",
    "    ## MODEL AND OPTIMIZER\n",
    "    model = LeNet5() |> device\n",
    "    @info \"LeNet5 model: $(num_params(model)) trainable params\"    \n",
    "    \n",
    "    ps = Flux.params(model)  \n",
    "\n",
    "    opt = ADAM(args.η) \n",
    "    if args.λ > 0 # add weight decay, equivalent to L2 regularization\n",
    "        opt = Optimiser(opt, WeightDecay(args.λ))\n",
    "    end\n",
    "    \n",
    "    \n",
    "    ## TRAINING\n",
    "    @info \"Start Training\"\n",
    "    report(0)\n",
    "    for epoch in 1:args.epochs\n",
    "        @showprogress for (x, y) in train_loader\n",
    "            x, y = x |> device, y |> device\n",
    "            gs = Flux.gradient(ps) do\n",
    "                    ŷ = model(x)\n",
    "                    loss(ŷ, y)\n",
    "                end\n",
    "\n",
    "            Flux.Optimise.update!(opt, ps, gs)\n",
    "        end\n",
    "    end\n",
    "end\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
